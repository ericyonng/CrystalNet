在 MongoDB 中，单个文档大小限制为 16MB，但可以通过 **分片存储 + 引用关联** 或 **GridFS 扩展存储** 的方式，将数据统一关联到 `Player` 表中，并通过 `PlayerId` 查询。以下是具体方案：

------

### **方案 1：分片存储 + 引用关联**

#### **核心思路**

- **小数据直接存储**：当数据 ≤16MB 时，直接以 `Player` 表的字段存储。
- **大数据分片存储**：当数据 >16MB 时，将数据分片存储在 `Player` 表的多个文档中，通过 `PlayerId` 和分片编号关联。

#### **数据结构设计**

```
// Player 表结构
{
  "_id": ObjectId,
  "PlayerId": "123",           // 唯一标识
  "binaryData": BinData(...),   // ≤16MB 时直接存储
  "isChunked": false,          // 是否分片存储
  "chunks": []                 // 分片存储时记录分片ID列表（关联其他文档）
}

// 分片存储的文档结构（同一集合）
{
  "_id": ObjectId,
  "PlayerId": "123",           // 关联 PlayerId
  "chunkIndex": 0,             // 分片编号
  "binaryChunk": BinData(...)  // 分片数据（每片 ≤16MB）
}
```

#### **操作流程**

1. **写入数据**：

   ```
   // 判断数据大小
   if (data_size <= 16MB) {
       // 直接存储到 Player 表
       player_col.insert_one(document{}
           << "PlayerId" << "123"
           << "binaryData" << bin_data
           << "isChunked" << false
           << finalize
       );
   } else {
       // 分片存储（例如每片 15MB）
       std::vector<ObjectId> chunk_ids;
       for (size_t i = 0; i < total_chunks; ++i) {
           auto chunk_doc = document{}
               << "PlayerId" << "123"
               << "chunkIndex" << static_cast<int>(i)
               << "binaryChunk" << bin_chunk_data[i]
               << finalize;
           auto result = player_col.insert_one(chunk_doc.view());
           chunk_ids.push_back(result->inserted_id());
       }
   
       // 记录分片信息到主文档
       player_col.insert_one(document{}
           << "PlayerId" << "123"
           << "isChunked" << true
           << "chunks" << open_array
               << [chunk_ids...]
           << close_array
           << finalize
       );
   }
   ```

2. **通过 `PlayerId` 查询**：

   ```
   // 查找主文档
   auto main_doc = player_col.find_one(document{} << "PlayerId" << "123" << finalize);
   
   if (main_doc["isChunked"].get_bool()) {
       // 分片数据：按 chunks 数组中的 ID 查询所有分片
       auto chunk_ids = main_doc["chunks"].get_array().value;
       for (auto&& chunk_id : chunk_ids) {
           auto chunk_doc = player_col.find_one(document{} << "_id" << chunk_id << finalize);
           // 合并分片数据...
       }
   } else {
       // 直接读取 binaryData
       auto data = main_doc["binaryData"].get_binary();
   }
   ```

------

### **方案 2：GridFS 扩展存储**

#### **核心思路**

- **统一存储**：所有数据（无论大小）通过 GridFS 存储，但在 `Player` 表中记录 GridFS 文件的引用。
- **透明访问**：通过 `PlayerId` 查询到 GridFS 文件 ID，再自动读取数据。

#### **数据结构设计**

```
// Player 表结构
{
  "_id": ObjectId,
  "PlayerId": "123",
  "fileRef": ObjectId("...")  // 关联 GridFS 文件 ID
}

// GridFS 自动分片存储
// fs.files 集合
{
  "_id": ObjectId("..."),     // 文件 ID（对应 fileRef）
  "filename": "player_data_123",
  "metadata": { "PlayerId": "123" }
}

// fs.chunks 集合（自动创建）
{
  "files_id": ObjectId("..."),  // 关联 fs.files._id
  "n": 0,                       // 分片编号
  "data": BinData(...)          // 分片数据
}
```

#### **操作流程**

1. **写入数据**：

   ```
   // 创建 GridFS 存储桶
   auto bucket = db.gridfs_bucket();
   
   // 上传文件到 GridFS（自动分片）
   auto uploader = bucket.open_upload_stream("player_data_123");
   uploader.write(data_ptr, data_size);
   auto result = uploader.close();
   
   // 记录关联关系到 Player 表
   player_col.insert_one(document{}
       << "PlayerId" << "123"
       << "fileRef" << result.id()
       << finalize
   );
   ```

2. **通过 `PlayerId` 查询**：

   ```
   // 从 Player 表获取 GridFS 文件 ID
   auto player_doc = player_col.find_one(document{} << "PlayerId" << "123" << finalize);
   auto file_id = player_doc["fileRef"].get_oid().value;
   
   // 从 GridFS 下载文件
   auto downloader = bucket.open_download_stream(file_id);
   std::vector<uint8_t> data;
   while (auto chunk = downloader.read(chunk_size)) {
       data.insert(data.end(), chunk.data(), chunk.data() + chunk.length());
   }
   ```

------

### **两种方案对比**

| **方案**        | **优点**                         | **缺点**                             |
| --------------- | -------------------------------- | ------------------------------------ |
| 分片存储 + 引用 | 数据统一存储在 `Player` 表       | 需要手动管理分片逻辑                 |
| GridFS 扩展存储 | 自动分片、标准方案、无需额外代码 | 数据物理上分散在多个集合（逻辑统一） |

------

### **推荐实现**

- **直接使用 GridFS**：利用 MongoDB 原生的大文件管理能力，代码更简洁。

- **在 `Player` 表中维护 `fileRef`**：通过 `PlayerId` 直接关联文件 ID，保证查询效率。

- 

  数据访问封装

  ：

  ```
  class PlayerDataManager {
  private:
      mongocxx::collection player_col;
      mongocxx::gridfs::bucket bucket;
  
  public:
      // 写入数据（自动处理大小）
      void saveData(const std::string& playerId, const uint8_t* data, size_t size) {
          auto uploader = bucket.open_upload_stream("player_data_" + playerId);
          uploader.write(data, size);
          auto result = uploader.close();
  
          // 更新 Player 表
          player_col.update_one(
              document{} << "PlayerId" << playerId << finalize,
              document{} << "$set" << open_document
                  << "fileRef" << result.id()
              << close_document << finalize,
              options::update().upsert(true)
          );
      }
  
      // 读取数据
      std::vector<uint8_t> loadData(const std::string& playerId) {
          auto player_doc = player_col.find_one(document{} << "PlayerId" << playerId << finalize);
          if (!player_doc) throw std::runtime_error("Player not found");
  
          auto file_id = player_doc->view()["fileRef"].get_oid().value;
          auto downloader = bucket.open_download_stream(file_id);
  
          std::vector<uint8_t> data;
          while (auto chunk = downloader.read(1024)) {
              data.insert(data.end(), chunk.data(), chunk.data() + chunk.length());
          }
          return data;
      }
  };
  ```

------

### **总结**

通过 **GridFS + Player 表引用** 的方案，既能满足大文件存储需求，又能通过 `PlayerId` 快速查询数据。所有数据逻辑上集中在 `Player` 表管理，物理存储对业务透明，是最优解。